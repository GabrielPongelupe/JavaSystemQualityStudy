#!/usr/bin/env python3
"""
An√°lise estat√≠stica e gera√ß√£o de relat√≥rio final
"""
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from datetime import datetime
import os

def load_analysis_data(csv_file):
    """Carrega dados da an√°lise completa"""
    df = pd.read_csv(csv_file)
    print(f"Dados carregados: {len(df)} reposit√≥rios")
    return df

def clean_data(df):
    """Limpa dados para an√°lise"""
    # Remover linhas com valores nulos cr√≠ticos
    critical_cols = ['stars', 'cbo_mean', 'dit_mean', 'lcom_mean']
    available_critical = [col for col in critical_cols if col in df.columns]
    
    if not available_critical:
        print("‚ö†Ô∏è  Nenhuma coluna cr√≠tica encontrada")
        return None
    
    clean_df = df[available_critical].dropna()
    
    # Remover outliers extremos
    for col in clean_df.select_dtypes(include=[np.number]).columns:
        Q1 = clean_df[col].quantile(0.25)
        Q3 = clean_df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        clean_df = clean_df[(clean_df[col] >= lower_bound) & (clean_df[col] <= upper_bound)]
    
    print(f"Dados limpos: {len(clean_df)} reposit√≥rios")
    return clean_df

def analyze_correlations(df):
    """Analisa correla√ß√µes entre m√©tricas"""
    print("\n" + "="*60)
    print("AN√ÅLISE DE CORRELA√á√ïES")
    print("="*60)
    
    # Vari√°veis de processo e qualidade
    process_vars = ['stars', 'age_years', 'releases', 'size_kb', 'loc']
    quality_vars = ['cbo_mean', 'dit_mean', 'lcom_mean', 'wmc_mean']
    
    # Filtrar vari√°veis dispon√≠veis
    available_process = [var for var in process_vars if var in df.columns]
    available_quality = [var for var in quality_vars if var in df.columns]
    
    if not available_process or not available_quality:
        print("‚ö†Ô∏è  Vari√°veis insuficientes para an√°lise")
        return None
    
    results = {}
    
    print(f"Analisando {len(df)} reposit√≥rios com dados completos")
    
    # Mapeamento das quest√µes de pesquisa
    rq_mappings = {
        'RQ01': ('stars', 'Popularidade'),
        'RQ02': ('age_years', 'Maturidade'),
        'RQ03': ('releases', 'Atividade'),
        'RQ04': ('size_kb', 'Tamanho')
    }
    
    for rq, (process_var, process_name) in rq_mappings.items():
        if process_var not in df.columns:
            continue
            
        print(f"\n--- {rq}: {process_name} vs Qualidade ---")
        results[rq] = {}
        
        for quality_var in available_quality:
            if quality_var in df.columns:
                # Remover valores nulos
                clean_data = df[[process_var, quality_var]].dropna()
                
                if len(clean_data) > 3:
                    # Correla√ß√£o de Pearson
                    pearson_r, pearson_p = stats.pearsonr(clean_data[process_var], clean_data[quality_var])
                    
                    # Correla√ß√£o de Spearman
                    spearman_r, spearman_p = stats.spearmanr(clean_data[process_var], clean_data[quality_var])
                    
                    results[rq][quality_var] = {
                        'pearson_r': pearson_r,
                        'pearson_p': pearson_p,
                        'spearman_r': spearman_r,
                        'spearman_p': spearman_p,
                        'n': len(clean_data)
                    }
                    
                    # Interpreta√ß√£o
                    strength = "forte" if abs(pearson_r) > 0.7 else "moderada" if abs(pearson_r) > 0.3 else "fraca"
                    direction = "positiva" if pearson_r > 0 else "negativa"
                    significance = "significativa" if pearson_p < 0.05 else "n√£o significativa"
                    
                    print(f"  {quality_var}: r={pearson_r:.3f} (p={pearson_p:.3f}) - {strength} {direction} {significance}")
    
    return results

def create_visualizations(df, output_dir):
    """Cria visualiza√ß√µes dos dados"""
    print("\n" + "="*60)
    print("GERANDO VISUALIZA√á√ïES")
    print("="*60)
    
    os.makedirs(output_dir, exist_ok=True)
    
    # Configura√ß√£o do estilo
    plt.style.use('default')
    sns.set_palette("husl")
    
    # 1. Matriz de correla√ß√£o
    numeric_cols = ['stars', 'age_years', 'releases', 'size_kb', 'loc', 
                   'cbo_mean', 'dit_mean', 'lcom_mean', 'wmc_mean']
    available_cols = [col for col in numeric_cols if col in df.columns]
    
    if len(available_cols) > 2:
        corr_matrix = df[available_cols].corr()
        
        plt.figure(figsize=(12, 10))
        mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
        sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,
                   square=True, linewidths=0.5, cbar_kws={"shrink": 0.8})
        plt.title('Matriz de Correla√ß√£o - M√©tricas de Processo vs Qualidade', fontsize=14)
        plt.tight_layout()
        plt.savefig(f"{output_dir}/correlation_matrix.png", dpi=300, bbox_inches='tight')
        plt.close()
        print("‚úì Matriz de correla√ß√£o salva")
    
    # 2. Scatter plots para cada RQ
    rq_mappings = {
        'RQ01': ('stars', 'Popularidade (Estrelas)'),
        'RQ02': ('age_years', 'Maturidade (Anos)'),
        'RQ03': ('releases', 'Atividade (Releases)'),
        'RQ04': ('size_kb', 'Tamanho (KB)')
    }
    
    quality_vars = ['cbo_mean', 'dit_mean', 'lcom_mean']
    
    for rq, (process_var, process_name) in rq_mappings.items():
        if process_var not in df.columns:
            continue
            
        fig, axes = plt.subplots(1, 3, figsize=(18, 6))
        fig.suptitle(f'{rq}: {process_name} vs Qualidade', fontsize=16)
        
        for i, quality_var in enumerate(quality_vars):
            if quality_var in df.columns:
                # Remover valores nulos
                plot_data = df[[process_var, quality_var]].dropna()
                
                if len(plot_data) > 0:
                    # Scatter plot
                    axes[i].scatter(plot_data[process_var], plot_data[quality_var], 
                                  alpha=0.6, s=50, color='blue')
                    
                    # Linha de tend√™ncia
                    z = np.polyfit(plot_data[process_var], plot_data[quality_var], 1)
                    p = np.poly1d(z)
                    axes[i].plot(plot_data[process_var], p(plot_data[process_var]), 
                               "r--", alpha=0.8, linewidth=2)
                    
                    # Correla√ß√£o
                    corr = plot_data[process_var].corr(plot_data[quality_var])
                    axes[i].set_title(f'{quality_var}\n(r = {corr:.3f})')
                    axes[i].set_xlabel(process_name)
                    axes[i].set_ylabel(quality_var.replace('_', ' ').title())
                    axes[i].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(f"{output_dir}/scatter_{rq.lower()}.png", dpi=300, bbox_inches='tight')
        plt.close()
        print(f"‚úì Scatter plot {rq} salvo")
    
    # 3. Distribui√ß√µes das m√©tricas
    quality_vars = ['cbo_mean', 'dit_mean', 'lcom_mean', 'wmc_mean']
    available_vars = [var for var in quality_vars if var in df.columns]
    
    if available_vars:
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        axes = axes.flatten()
        
        for i, var in enumerate(available_vars[:4]):
            if i < len(axes):
                data = df[var].dropna()
                if len(data) > 0:
                    axes[i].hist(data, bins=30, alpha=0.7, edgecolor='black')
                    mean_val = data.mean()
                    median_val = data.median()
                    axes[i].axvline(mean_val, color='red', linestyle='--', 
                                  label=f'M√©dia: {mean_val:.2f}')
                    axes[i].axvline(median_val, color='green', linestyle='--', 
                                  label=f'Mediana: {median_val:.2f}')
                    axes[i].set_title(f'Distribui√ß√£o de {var.replace("_", " ").title()}')
                    axes[i].set_xlabel(var.replace('_', ' ').title())
                    axes[i].set_ylabel('Frequ√™ncia')
                    axes[i].legend()
                    axes[i].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(f"{output_dir}/distributions.png", dpi=300, bbox_inches='tight')
        plt.close()
        print("‚úì Distribui√ß√µes salvas")
    
    print(f"Visualiza√ß√µes salvas em: {output_dir}/")

def generate_final_report(df, correlation_results, output_file):
    """Gera relat√≥rio final"""
    print("\n" + "="*60)
    print("GERANDO RELAT√ìRIO FINAL")
    print("="*60)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("# Relat√≥rio Final - Lab02S02\n")
        f.write("## Estudo das Caracter√≠sticas de Qualidade de Sistemas Java\n\n")
        f.write(f"**Data de gera√ß√£o:** {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\n")
        f.write(f"**Reposit√≥rios analisados:** {len(df)}\n\n")
        
        # Introdu√ß√£o
        f.write("## 1. Introdu√ß√£o\n\n")
        f.write("Este relat√≥rio apresenta a an√°lise de qualidade de sistemas Java desenvolvidos ")
        f.write("em reposit√≥rios open-source do GitHub. O objetivo √© investigar a rela√ß√£o entre ")
        f.write("caracter√≠sticas do processo de desenvolvimento e m√©tricas de qualidade de c√≥digo.\n\n")
        
        # Hip√≥teses
        f.write("## 2. Hip√≥teses\n\n")
        hypotheses = {
            'RQ01': {
                'question': 'Qual a rela√ß√£o entre a popularidade dos reposit√≥rios e suas caracter√≠sticas de qualidade?',
                'hypothesis': 'Reposit√≥rios mais populares (mais estrelas) tendem a ter melhor qualidade de c√≥digo.'
            },
            'RQ02': {
                'question': 'Qual a rela√ß√£o entre a maturidade dos reposit√≥rios e suas caracter√≠sticas de qualidade?',
                'hypothesis': 'Reposit√≥rios mais maduros (mais antigos) podem ter pior qualidade devido ao d√©bito t√©cnico.'
            },
            'RQ03': {
                'question': 'Qual a rela√ß√£o entre a atividade dos reposit√≥rios e suas caracter√≠sticas de qualidade?',
                'hypothesis': 'Reposit√≥rios mais ativos (mais releases) mant√™m melhor qualidade.'
            },
            'RQ04': {
                'question': 'Qual a rela√ß√£o entre o tamanho dos reposit√≥rios e suas caracter√≠sticas de qualidade?',
                'hypothesis': 'Reposit√≥rios maiores tendem a ter pior qualidade devido √† complexidade.'
            }
        }
        
        for rq, data in hypotheses.items():
            f.write(f"### {rq}\n")
            f.write(f"**Pergunta:** {data['question']}\n\n")
            f.write(f"**Hip√≥tese:** {data['hypothesis']}\n\n")
        
        # Metodologia
        f.write("## 3. Metodologia\n\n")
        f.write("### 3.1 Coleta de Dados\n")
        f.write("- **Reposit√≥rios:** Top 1000 reposit√≥rios Java mais populares do GitHub\n")
        f.write("- **M√©tricas de processo:** Popularidade, maturidade, atividade, tamanho\n")
        f.write("- **M√©tricas de qualidade:** CBO, DIT, LCOM, WMC (via CK Metrics)\n")
        f.write("- **An√°lise estat√≠stica:** Correla√ß√µes de Pearson e Spearman\n\n")
        
        # Resultados
        f.write("## 4. Resultados\n\n")
        
        # Estat√≠sticas descritivas
        f.write("### 4.1 Estat√≠sticas Descritivas\n\n")
        numeric_cols = ['stars', 'age_years', 'releases', 'size_kb', 'loc', 
                       'cbo_mean', 'dit_mean', 'lcom_mean', 'wmc_mean']
        available_cols = [col for col in numeric_cols if col in df.columns]
        
        if available_cols:
            desc_stats = df[available_cols].describe()
            f.write("```\n")
            f.write(desc_stats.to_string())
            f.write("\n```\n\n")
        
        # Correla√ß√µes
        f.write("### 4.2 An√°lise de Correla√ß√µes\n\n")
        if correlation_results:
            for rq, correlations in correlation_results.items():
                f.write(f"#### {rq}\n\n")
                for metric, stats in correlations.items():
                    f.write(f"**{metric}:**\n")
                    f.write(f"- Pearson r = {stats['pearson_r']:.3f} (p = {stats['pearson_p']:.3f})\n")
                    f.write(f"- Spearman œÅ = {stats['spearman_r']:.3f} (p = {stats['spearman_p']:.3f})\n")
                    f.write(f"- N = {stats['n']}\n\n")
        
        # Discuss√£o
        f.write("## 5. Discuss√£o\n\n")
        f.write("### 5.1 Principais Descobertas\n")
        f.write("- An√°lise baseada em dados reais de reposit√≥rios Java\n")
        f.write("- Correla√ß√µes entre caracter√≠sticas de processo e qualidade\n")
        f.write("- Visualiza√ß√µes para interpreta√ß√£o dos resultados\n\n")
        
        f.write("### 5.2 Limita√ß√µes\n")
        f.write("- An√°lise baseada em snapshot dos reposit√≥rios\n")
        f.write("- M√©tricas CK podem n√£o capturar todos os aspectos de qualidade\n")
        f.write("- Correla√ß√£o n√£o implica causalidade\n\n")
        
        f.write("## 6. Conclus√µes\n\n")
        f.write("Este estudo fornece insights sobre a rela√ß√£o entre caracter√≠sticas do processo ")
        f.write("de desenvolvimento e qualidade de c√≥digo em reposit√≥rios Java open-source. ")
        f.write("Os resultados podem informar pr√°ticas de desenvolvimento e pol√≠ticas de qualidade.\n")
    
    print(f"Relat√≥rio final salvo em: {output_file}")

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="An√°lise estat√≠stica e relat√≥rio final")
    parser.add_argument("--data", required=True, help="CSV com dados da an√°lise completa")
    parser.add_argument("--output", default="results", help="Diret√≥rio de sa√≠da")
    
    args = parser.parse_args()
    
    # Carregar dados
    df = load_analysis_data(args.data)
    
    # Limpar dados
    clean_df = clean_data(df)
    if clean_df is None:
        print("‚ùå Dados insuficientes para an√°lise")
        return
    
    # An√°lise de correla√ß√µes
    correlation_results = analyze_correlations(clean_df)
    
    # Visualiza√ß√µes
    plots_dir = os.path.join(args.output, "plots")
    create_visualizations(clean_df, plots_dir)
    
    # Relat√≥rio final
    report_file = os.path.join(args.output, "relatorio_final_lab02s02.md")
    generate_final_report(clean_df, correlation_results, report_file)
    
    print("\n" + "="*60)
    print("AN√ÅLISE ESTAT√çSTICA CONCLU√çDA!")
    print("="*60)
    print(f"üìä Dados analisados: {len(clean_df)} reposit√≥rios")
    print(f"üìÅ Resultados em: {args.output}/")
    print(f"üìÑ Relat√≥rio: {report_file}")

if __name__ == "__main__":
    main()
